{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a notebook to run a simple binary classification algorithm, using Decision Trees.\n",
    "\n",
    "#Author: Viviana Acquaviva\n",
    "#License: BSD but really should be TBD - just be nice.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "#Notes: \n",
    "\n",
    "#Data come from here\n",
    "#from astroML.datasets import fetch_rrlyrae_combined\n",
    "#X, y = fetch_rrlyrae_combined()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok, now time to get real!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous data set was just a small/curated selection of the total, which is the one below. Let's read it in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xbig = pd.read_csv('RRLyrae_features.txt', names = ['u-g', 'g-r', 'r-i', 'i-z'])\n",
    "ybig = pd.read_csv('RRLyrae_labels.txt', header = None).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot ALL the data, ahem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Xbig['u-g'], Xbig['r-i'], \\\n",
    "            c = ybig.iloc[:,0].values, marker = '*', s =20, label = None, cmap = 'brg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's take a look at how many positive examples (variable stars) we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ybig.sum() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ybig.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do some data thinking.\n",
    "\n",
    "<br>\n",
    "What is noticeable about this data set?\n",
    "\n",
    "Do you expect a decision tree to be an optimal classifier, based on the shape of the data?\n",
    "\n",
    "How would a classifier that puts everything in the \"non-RR Lyrae\" box fare on this data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answers go here :) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how our previous algorithm would fare on this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Xbig['u-g'], Xbig['r-i'], \\\n",
    "            c = ybig.iloc[:,0].values, marker = '*', s =20, label = None, cmap = 'brg')\n",
    "plt.axvline(x=0.218, linewidth =1, label = '1st split')\n",
    "plt.axvline(x=0.147, linewidth =1, ls = '--', label = '2nd split')\n",
    "plt.axhline(y=0.035, linewidth =1, ls = '-.', xmin = 0.53, xmax=0.65, label = '3rd split')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: How is our old tree doing? What is it getting right and wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answers go here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do our training process again! Here we don't have separate train and test splits so we can create them, we'll call them X_trainb, X_testb etc (for \"big\"). Note: we are not doing cross validation yet, which is bad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainb, X_testb, y_trainb, y_testb = train_test_split(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill\n",
    "\n",
    "modelbig = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the same plotting routine as above to visualize the new tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(\n",
    "            modelbig, #note name change\n",
    "            out_file =  dot_data,\n",
    "            feature_names = list(X_trainb.columns), #here too\n",
    "            class_names = ['Not var','Var'],\n",
    "            filled = True,\n",
    "rounded = True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at those colors and then evaluate how the tree is doing on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is high, as expected! But is it meaningful? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at other metrics, and at the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define recall, estimate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define precision, estimate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_testb, ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap: what have we seen so far?\n",
    "\n",
    "Let's talk about what we should be doing to optimize this classifier, going back to the tools we mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ideas here.\n",
    "\n",
    "1. \n",
    "\n",
    "2. \n",
    "\n",
    "3. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelbig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can customize this cell as we try new models\n",
    "\n",
    "modelX = DecisionTreeClassifier(class_weight='balanced')\n",
    "modelX.fit(X_trainb,y_trainb)\n",
    "dot_data = StringIO()\n",
    "export_graphviz(\n",
    "            modelX,\n",
    "            out_file =  dot_data,\n",
    "            feature_names = list(X_trainb.columns),\n",
    "            class_names = ['Not var','Var'],\n",
    "            filled = True,\n",
    "rounded = True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And then look at some of these to see what is happening\n",
    "\n",
    "print(metrics.accuracy_score(y_trainb, modelX.predict(X_trainb)))\n",
    "print(metrics.precision_score(y_trainb, modelX.predict(X_trainb)))\n",
    "print(metrics.recall_score(y_trainb, modelX.predict(X_trainb)))\n",
    "\n",
    "print(metrics.accuracy_score(y_testb, modelX.predict(X_testb)))\n",
    "print(metrics.precision_score(y_testb, modelX.predict(X_testb)))\n",
    "print(metrics.recall_score(y_testb, modelX.predict(X_testb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  How to do k-fold cross validation: cross_val_score and cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(shuffle = True, n_splits = 5)\n",
    "\n",
    "scores = cross_val_score(modelX, Xbig, ybig, cv = cv, scoring = .... )\n",
    "\n",
    "scores.mean(), scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = (modelX, Xbig, ybig, cv = cv) #No scoring strategy here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y, ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
